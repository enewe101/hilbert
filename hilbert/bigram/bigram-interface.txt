factories.py

    In this context, we want to be dealing with a Bigram representing the 
    whole Dataset.  This Bigram should inheret from Dataset.  This bigram
    will be used to generate BigramSector instances within the child process.


loader.py -- 

    The role currently played by Bigram should actually be done by BigramSector.
    So, what needs to happen is that the call to _setup should build a
    BigramSector instead of the current Bigram.

    Instead of doing ShardSector.load, it should do self.bigram_sector =
    self.Bigram.get_sector().  Sectorizing should be a subsampling operation
    that mimics what is done during save sector.  (In fact, it would be
    cleaner if save_sector would first create a sector using a get_sector(),
    and then call the generated sector's save method.

    (Can all of the subsequently accessed functionality be built in BigramBase?
    This should determine how we name the uses of Bigram / BigramSector there.)

